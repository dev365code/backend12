"""
í¬ë¦½í†  ë‰´ìŠ¤ ê²€ìƒ‰ Tool
ê¸°ì¡´ ë²¡í„° ê²€ìƒ‰ ê¸°ëŠ¥ì„ LangChain Toolë¡œ ë˜í•‘
"""

import logging
import asyncio
from typing import Any, Dict
from langchain.tools import BaseTool
from pydantic import Field

logger = logging.getLogger(__name__)

class CryptoNewsSearchTool(BaseTool):
    """í¬ë¦½í†  ë‰´ìŠ¤ ë²¡í„° ê²€ìƒ‰ ë„êµ¬"""
    
    name: str = "crypto_news_search"
    description: str = """
    ì•”í˜¸í™”í ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    ì‚¬ìš© ì˜ˆì‹œ:
    - "ë¹„íŠ¸ì½”ì¸ ìµœê·¼ ë‰´ìŠ¤"
    - "ì´ë”ë¦¬ì›€ ê°€ê²© ìƒìŠ¹ ì†Œì‹"
    - "ì•”í˜¸í™”í ê·œì œ ë‰´ìŠ¤"
    
    ì…ë ¥: ê²€ìƒ‰í•˜ê³  ì‹¶ì€ í‚¤ì›Œë“œë‚˜ ì§ˆë¬¸
    ì¶œë ¥: ê´€ë ¨ ë‰´ìŠ¤ ëª©ë¡ê³¼ ìš”ì•½
    """
    
    vector_service: Any = Field(description="ë²¡í„° ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤")
    
    def _run(self, query: str) -> str:
        """ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤í–‰ - ê°œì„ ëœ ë²„ì „"""
        try:
            logger.info(f"ğŸ“° ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤í–‰: '{query}'")
            
            # ì‚¬ìš©ì ìš”ì²­ëŸ‰ íŒŒì•…
            requested_count = 3  # ê¸°ë³¸ê°’
            if 'ë‹¤' in query or 'ëª¨ë“ ' in query or 'ì „ì²´' in query or 'ëª¨ë‘' in query:
                requested_count = 10  # ë” ë§ì´ ìš”ì²­í•œ ê²½ìš°
            elif any(num in query for num in ['5ê°œ', 'ë‹¤ì„¯', '5']):
                requested_count = 5
            
            logger.debug(f"ê²€ìƒ‰ íŒŒë¼ë¯¸í„° - ìš”ì²­ëŸ‰: {requested_count}ê°œ")
            
            # ì§ì ‘ DB ê²€ìƒ‰ìœ¼ë¡œ ë‹¨ìˆœí™” (ë²¡í„° ê²€ìƒ‰ ë¬¸ì œ ìš°íšŒ)
            try:
                import psycopg2
                from psycopg2.extras import RealDictCursor
                
                conn = psycopg2.connect(
                    host='localhost',
                    port=5435,
                    database='mydb',
                    user='myuser',
                    password='mypassword'
                )
                
                with conn.cursor(cursor_factory=RealDictCursor) as cur:
                    logger.debug(f"ì§ì ‘ DB ê²€ìƒ‰ ì‹¤í–‰ - í‚¤ì›Œë“œ: '{query}'")
                    
                    # í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ + ìµœì‹ ìˆœ ì •ë ¬
                    search_conditions = []
                    search_params = []
                    
                    # ê¸°ë³¸ í‚¤ì›Œë“œ ê²€ìƒ‰
                    basic_keywords = ['ë¹„íŠ¸ì½”ì¸', 'bitcoin', 'btc', 'ì•”í˜¸í™”í', 'crypto', 'ethereum', 'eth']
                    
                    # ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
                    query_lower = query.lower()
                    found_keywords = []
                    
                    for keyword in basic_keywords:
                        if keyword in query_lower:
                            found_keywords.append(keyword)
                    
                    # êµ¬ì²´ì ì¸ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í•´ë‹¹ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰
                    if found_keywords:
                        keyword_conditions = []
                        for keyword in found_keywords:
                            keyword_conditions.append('(title ILIKE %s OR summary ILIKE %s)')
                            search_params.extend([f'%{keyword}%', f'%{keyword}%'])
                        
                        search_query = f'''
                            SELECT id, title, summary, url, source, published_date,
                                   CASE 
                                       WHEN title ILIKE %s THEN 0.9
                                       WHEN summary ILIKE %s THEN 0.7
                                       ELSE 0.5
                                   END as relevance_score
                            FROM crypto_news 
                            WHERE ({' OR '.join(keyword_conditions)})
                            ORDER BY relevance_score DESC, published_date DESC 
                            LIMIT %s
                        '''
                        search_params = [f'%{found_keywords[0]}%', f'%{found_keywords[0]}%'] + search_params + [requested_count]
                        
                    else:
                        # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ìµœì‹  ë‰´ìŠ¤ ì œê³µ
                        search_query = '''
                            SELECT id, title, summary, url, source, published_date,
                                   0.8 as relevance_score
                            FROM crypto_news 
                            ORDER BY published_date DESC 
                            LIMIT %s
                        '''
                        search_params = [requested_count]
                    
                    cur.execute(search_query, search_params)
                    results = cur.fetchall()
                    
                    logger.info(f"ì§ì ‘ DB ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
                    
                    if results:
                        # ê²°ê³¼ í¬ë§·íŒ…
                        formatted_results = f"ğŸ“° '{query}' ê²€ìƒ‰ ê²°ê³¼ ({len(results)}ê°œ):\n\n"
                        
                        for i, result in enumerate(results, 1):
                            title = result['title']
                            if len(title) > 80:
                                title = title[:80] + "..."
                            
                            summary = result.get('summary', '')  
                            if summary and len(summary) > 150:
                                summary = summary[:150] + "..."
                            elif not summary:
                                summary = 'ìš”ì•½ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.'
                            
                            # ê´€ë ¨ë„ë¥¼ ë³„ì ìœ¼ë¡œ í‘œì‹œ
                            relevance = result.get('relevance_score', 0.5)
                            star_rating = "â­" * min(max(int(relevance * 5), 1), 5)
                            
                            # ë‚ ì§œ í¬ë§·íŒ…
                            pub_date = result.get('published_date', '')
                            if isinstance(pub_date, str) and 'T' in pub_date:
                                pub_date = pub_date.split('T')[0]
                            
                            formatted_results += f"{i}. **{title}**\n"
                            formatted_results += f"   {star_rating} ê´€ë ¨ë„: {relevance:.2f}\n"
                            if pub_date:
                                formatted_results += f"   ğŸ“… {pub_date}\n"
                            formatted_results += f"   ğŸ“– {summary}\n"
                            formatted_results += f"   ğŸ”— ì¶œì²˜: {result.get('source', 'ì¶œì²˜ ë¯¸ìƒ')}\n\n"
                        
                        formatted_results += f"ğŸ’¡ ì´ {len(results)}ê°œì˜ ë‰´ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
                        
                        if len(results) < requested_count:
                            formatted_results += f"\n\nğŸ”„ ë” ë§ì€ ë‰´ìŠ¤ë¥¼ ì›í•˜ì‹œë©´ ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì—¬ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•´ë³´ì„¸ìš”."
                        
                        conn.close()
                        logger.info("ë‰´ìŠ¤ ê²€ìƒ‰ ì„±ê³µ, ê²°ê³¼ ë°˜í™˜")
                        return formatted_results
                    
                    else:
                        # ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ìµœì‹  ë‰´ìŠ¤ë¼ë„ ì œê³µ
                        cur.execute('''
                            SELECT id, title, summary, url, source, published_date
                            FROM crypto_news 
                            ORDER BY published_date DESC 
                            LIMIT 3
                        ''')
                        
                        latest_results = cur.fetchall()
                        conn.close()
                        
                        if latest_results:
                            formatted_results = f"'{query}'ì™€ ì§ì ‘ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í•´ì„œ ìµœì‹  ì•”í˜¸í™”í ë‰´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤:\n\n"
                            
                            for i, result in enumerate(latest_results, 1):
                                title = result['title']
                                if len(title) > 70:
                                    title = title[:70] + "..."
                                
                                summary = result.get('summary', '')
                                if summary and len(summary) > 120:
                                    summary = summary[:120] + "..."
                                
                                formatted_results += f"{i}. **{title}**\n"
                                formatted_results += f"   ğŸ“– {summary}\n"
                                formatted_results += f"   ğŸ“… {result.get('published_date', '')}\n"
                                formatted_results += f"   ğŸ”— ì¶œì²˜: {result.get('source', '')}\n\n"
                            
                            formatted_results += "ğŸ”„ ë” ê´€ë ¨ì„± ë†’ì€ ë‰´ìŠ¤ë¥¼ ìœ„í•´ ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•´ë³´ì„¸ìš”."
                            return formatted_results
                
                conn.close()
                
            except Exception as db_error:
                logger.error(f"âŒ ì§ì ‘ DB ê²€ìƒ‰ ì‹¤íŒ¨: {db_error}")
                results = []
            
            if not results:
                logger.warning("ëª¨ë“  ë²¡í„° ê²€ìƒ‰ ë°©ë²• ì‹¤íŒ¨, ê¸°ì¡´ í…Œì´ë¸”ì—ì„œ ì§ì ‘ ê²€ìƒ‰ ì‹œë„")
                # ê¸°ì¡´ í…Œì´ë¸”ì—ì„œ ê²€ìƒ‰ ì‹œë„ (ë°±ì—…) - OPENAI_API_KEY ì—†ì´ ì§ì ‘ DB ì—°ê²°
                try:
                    logger.debug("ê¸°ì¡´ í…Œì´ë¸” ì§ì ‘ ê²€ìƒ‰ ì‹œë„ (ì§ì ‘ DB ì—°ê²°)...")
                    import psycopg2
                    from psycopg2.extras import RealDictCursor
                    
                    # PgVector DBì— ì§ì ‘ ì—°ê²°
                    conn = psycopg2.connect(
                        host='localhost',
                        port=5435,
                        database='mydb',
                        user='myuser',
                        password='mypassword'
                    )
                    
                    with conn.cursor(cursor_factory=RealDictCursor) as cur:
                        logger.debug(f"SQL ì§ì ‘ ê²€ìƒ‰ ì‹¤í–‰ - í‚¤ì›Œë“œ: '{query}'")
                        
                        # í™•ì¥ëœ í‚¤ì›Œë“œ ê²€ìƒ‰
                        search_terms = [query]
                        
                        # íŠ¹ì • í‚¤ì›Œë“œì— ëŒ€í•œ í™•ì¥ ê²€ìƒ‰ì–´ ì¶”ê°€
                        if 'íŠ¸ëŸ¼í”„' in query.lower():
                            search_terms.extend(['trump', 'donald', 'ë„ë„ë“œ', 'ëŒ€í†µë ¹', 'president'])
                        elif 'ë°±ì•…ê´€' in query.lower():
                            search_terms.extend(['white house', 'whitehouse', 'ë¯¸êµ­', 'usa', 'ì •ë¶€', 'government'])
                        elif 'ì •ì±…' in query.lower():
                            search_terms.extend(['policy', 'regulation', 'ê·œì œ', 'sec', 'ì •ë¶€'])
                        elif 'etf' in query.lower():
                            search_terms.extend(['bitcoin etf', 'spot etf', 'ìƒì¥ì§€ìˆ˜í€ë“œ'])
                        
                        # ê° ê²€ìƒ‰ì–´ë¡œ ê²€ìƒ‰
                        all_results = []
                        for term in search_terms:
                            cur.execute("""
                                SELECT id, title, summary, url, source, published_date 
                                FROM crypto_news 
                                WHERE title ILIKE %s OR summary ILIKE %s 
                                ORDER BY published_date DESC 
                                LIMIT 5
                            """, (f'%{term}%', f'%{term}%'))
                            
                            term_results = cur.fetchall()
                            all_results.extend(term_results)
                        
                        # ì¤‘ë³µ ì œê±° (id ê¸°ì¤€)
                        seen_ids = set()
                        unique_results = []
                        for result in all_results:
                            if result['id'] not in seen_ids:
                                seen_ids.add(result['id'])
                                unique_results.append(result)
                        
                        fallback_results = unique_results[:3]  # ìµœëŒ€ 3ê°œ
                        logger.info(f"í™•ì¥ í‚¤ì›Œë“œ ê²€ìƒ‰ ì™„ë£Œ: {len(fallback_results)}ê°œ ê²°ê³¼")
                        
                        if fallback_results:
                            logger.debug("í™•ì¥ ê²€ìƒ‰ì—ì„œ ê²°ê³¼ ì°¾ìŒ, í¬ë§·íŒ… ì‹œì‘")
                            formatted_results = f"ğŸ“° '{query}' ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼:\n\n"
                            for i, result in enumerate(fallback_results, 1):
                                title = result['title'][:80] + "..." if len(result['title']) > 80 else result['title']
                                summary = result.get('summary', '')[:150] + "..." if result.get('summary') and len(result.get('summary', '')) > 150 else result.get('summary', 'ë‚´ìš© ì—†ìŒ')
                                
                                formatted_results += f"{i}. **{title}**\n"
                                formatted_results += f"   ğŸ“– {summary}\n"
                                formatted_results += f"   ğŸ“… {result.get('published_date', 'ë‚ ì§œ ë¯¸ìƒ')}\n"
                                formatted_results += f"   ğŸ”— ì¶œì²˜: {result.get('source', 'ì¶œì²˜ ë¯¸ìƒ')}\n\n"
                            
                            formatted_results += f"ğŸ’¡ ì´ {len(fallback_results)}ê°œì˜ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
                            logger.info("í™•ì¥ ê²€ìƒ‰ ì„±ê³µ, ê²°ê³¼ ë°˜í™˜")
                            conn.close()
                            return formatted_results
                        else:
                            # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ìµœì‹  ë‰´ìŠ¤ ì œê³µ
                            logger.info("ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, ìµœì‹  ë‰´ìŠ¤ ì œê³µ")
                            cur.execute("""
                                SELECT id, title, summary, url, source, published_date 
                                FROM crypto_news 
                                ORDER BY published_date DESC 
                                LIMIT 3
                            """)
                            
                            latest_news = cur.fetchall()
                            
                            if latest_news:
                                formatted_results = f"'{query}'ì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ì„œ, ëŒ€ì‹  ìµœì‹  ì•”í˜¸í™”í ë‰´ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤:\n\n"
                                
                                for i, result in enumerate(latest_news, 1):
                                    title = result['title'][:80] + "..." if len(result['title']) > 80 else result['title']
                                    summary = result.get('summary', '')[:120] + "..." if result.get('summary') and len(result.get('summary', '')) > 120 else result.get('summary', 'ë‚´ìš© ì—†ìŒ')
                                    
                                    formatted_results += f"{i}. **{title}**\n"
                                    formatted_results += f"   ğŸ“– {summary}\n"
                                    formatted_results += f"   ğŸ“… {result.get('published_date', 'ë‚ ì§œ ë¯¸ìƒ')}\n"
                                    formatted_results += f"   ğŸ”— ì¶œì²˜: {result.get('source', 'ì¶œì²˜ ë¯¸ìƒ')}\n\n"
                                
                                formatted_results += f"ğŸ”„ ë” êµ¬ì²´ì ì¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•˜ì‹œê±°ë‚˜, ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì—¬ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•´ë³´ì„¸ìš”."
                                conn.close()
                                return formatted_results
                            
                    conn.close()
                        
                except Exception as e:
                    logger.error(f"âŒ ê¸°ì¡´ í…Œì´ë¸” ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    logger.debug(f"ê¸°ì¡´ í…Œì´ë¸” ê²€ìƒ‰ ìƒì„¸ ì˜¤ë¥˜: {str(e)}")
                    if 'conn' in locals():
                        conn.close()
                
                logger.warning(f"ëª¨ë“  ê²€ìƒ‰ ë°©ë²• ì‹¤íŒ¨: '{query}' í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return f"'{query}'ì™€ ê´€ë ¨ëœ ë‰´ìŠ¤ë¥¼ í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ”„ **í•´ê²° ë°©ë²•:**\nâ€¢ ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš” (ì˜ˆ: 'ETF', 'ê·œì œ', 'ë¹„íŠ¸ì½”ì¸')\nâ€¢ ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•˜ì—¬ ìµœì‹  ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•´ë³´ì„¸ìš”\nâ€¢ ì¢€ ë” ì¼ë°˜ì ì¸ ìš©ì–´ë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”"
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = "ğŸ“° ê´€ë ¨ ë‰´ìŠ¤ ê²€ìƒ‰ ê²°ê³¼:\n\n"
            
            for i, result in enumerate(results, 1):
                # PgVector ì„œë¹„ìŠ¤ì˜ ê²°ê³¼ í˜•ì‹ì— ë§ì¶¤
                similarity_score = result.get('similarity', 0)
                title = result.get('title', 'ì œëª© ì—†ìŒ')
                summary = result.get('summary') or result.get('content', '')
                source = result.get('source', 'ì¶œì²˜ ë¯¸ìƒ')
                published_date = result.get('published_date', '')
                
                # ì œëª© ì •ë¦¬
                if len(title) > 80:
                    title = title[:80] + "..."
                
                # ìš”ì•½ ë‚´ìš© ì •ë¦¬
                if summary:
                    if len(summary) > 150:
                        summary = summary[:150] + "..."
                else:
                    summary = "ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
                # ìœ ì‚¬ë„ë¥¼ ë³„ì ìœ¼ë¡œ í‘œí˜„
                star_rating = "â­" * min(max(int(similarity_score * 5), 1), 5)
                
                # ë‚ ì§œ í¬ë§·íŒ…
                if published_date and isinstance(published_date, str):
                    try:
                        # ISO í˜•ì‹ ë‚ ì§œë¥¼ ê°„ë‹¨í•˜ê²Œ ë³€í™˜
                        if 'T' in published_date:
                            date_part = published_date.split('T')[0]
                            published_date = date_part
                    except:
                        pass
                
                formatted_results += f"{i}. **{title}**\n"
                formatted_results += f"   {star_rating} ê´€ë ¨ë„: {similarity_score:.2f}\n"
                if published_date:
                    formatted_results += f"   ğŸ“… {published_date}\n"
                formatted_results += f"   ğŸ“– {summary}\n"
                formatted_results += f"   ğŸ”— ì¶œì²˜: {source}\n\n"
            
            formatted_results += f"ğŸ’¡ ì´ {len(results)}ê°œì˜ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
            
            logger.info(f"âœ… ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return formatted_results
            
        except Exception as e:
            logger.error(f"âŒ ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def _arun(self, query: str) -> str:
        """ë¹„ë™ê¸° ë‰´ìŠ¤ ê²€ìƒ‰ ì‹¤í–‰"""
        return self._run(query)


class LatestNewsLookupTool(BaseTool):
    """ìµœì‹  ë‰´ìŠ¤ ì¡°íšŒ ë„êµ¬"""
    
    name: str = "latest_news_lookup"
    description: str = """
    ì•”í˜¸í™”í ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì‹œê°„ìˆœìœ¼ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    ì‚¬ìš© ì˜ˆì‹œ:
    - "ìµœì‹  ë‰´ìŠ¤"
    - "ì˜¤ëŠ˜ ì•”í˜¸í™”í ì†Œì‹"
    - "ìµœê·¼ ì—…ë°ì´íŠ¸"
    
    ì…ë ¥: "ìµœì‹ " ë˜ëŠ” "recent" ë“±ì˜ í‚¤ì›Œë“œ
    ì¶œë ¥: ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬ëœ ìµœì‹  ë‰´ìŠ¤ ëª©ë¡
    """
    
    vector_service: Any = Field(description="ë²¡í„° ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤")
    
    def _run(self, query: str = "ìµœì‹ ") -> str:
        """ìµœì‹  ë‰´ìŠ¤ ì¡°íšŒ ì‹¤í–‰"""
        try:
            logger.info(f"ğŸ“… ìµœì‹  ë‰´ìŠ¤ ì¡°íšŒ ì‹¤í–‰: {query}")
            
            # DualDatabaseServiceë¥¼ í†µí•œ ìµœì‹  ë‰´ìŠ¤ ì¡°íšŒ
            try:
                from services.dual_db_service import DualDatabaseService
                dual_db_service = DualDatabaseService()
                results = dual_db_service.get_recent_articles(hours=24, limit=5)
            except Exception as import_error:
                logger.error(f"DualDatabaseService import ì‹¤íŒ¨: {import_error}")
                # PgVector ì„œë¹„ìŠ¤ ë°±ì—…
                try:
                    from services.pgvector_service import PgVectorService
                    pgvector_service = PgVectorService()
                    results = pgvector_service.get_recent_articles(hours=24, limit=5)
                except Exception as backup_error:
                    logger.error(f"ë°±ì—… ì„œë¹„ìŠ¤ ì‹¤íŒ¨: {backup_error}")
                    # ê¸°ì¡´ ë²¡í„° ì„œë¹„ìŠ¤ ì‚¬ìš© (ìµœì¢… ë°±ì—…)
                    if hasattr(self.vector_service, 'get_latest_news'):
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            results = loop.run_until_complete(
                                self.vector_service.get_latest_news(limit=5)
                            )
                        finally:
                            loop.close()
                    else:
                        results = []
            
            if not results:
                return "ìµœì‹  ë‰´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì— ë‰´ìŠ¤ê°€ ì—†ê±°ë‚˜ ì—°ê²°ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = "ğŸ“… ìµœì‹  ì•”í˜¸í™”í ë‰´ìŠ¤ (ìµœê·¼ 24ì‹œê°„):\n\n"
            
            for i, result in enumerate(results, 1):
                title = result.get('title', 'ì œëª© ì—†ìŒ')
                summary = result.get('summary') or result.get('content', '')
                source = result.get('source', 'ì¶œì²˜ ë¯¸ìƒ')
                published_date = result.get('published_date', '')
                
                # ì œëª© ì •ë¦¬
                if len(title) > 70:
                    title = title[:70] + "..."
                
                # ìš”ì•½ ë‚´ìš© ì •ë¦¬
                if summary:
                    if len(summary) > 120:
                        summary = summary[:120] + "..."
                else:
                    summary = "ë‚´ìš©ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
                # ë‚ ì§œ í¬ë§·íŒ…
                if published_date and isinstance(published_date, str):
                    try:
                        if 'T' in published_date:
                            date_part = published_date.split('T')[0]
                            published_date = date_part
                    except:
                        pass
                
                formatted_results += f"{i}. **{title}**\n"
                if published_date:
                    formatted_results += f"   ğŸ“… {published_date}\n"
                formatted_results += f"   ğŸ“– {summary}\n"
                formatted_results += f"   ğŸ”— ì¶œì²˜: {source}\n\n"
            
            formatted_results += f"ğŸ’¡ ì´ {len(results)}ê°œì˜ ìµœì‹  ë‰´ìŠ¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤."
            
            logger.info(f"âœ… ìµœì‹  ë‰´ìŠ¤ ì¡°íšŒ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼")
            return formatted_results
            
        except Exception as e:
            logger.error(f"âŒ ìµœì‹  ë‰´ìŠ¤ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return f"ìµœì‹  ë‰´ìŠ¤ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}. ë°ì´í„°ë² ì´ìŠ¤ì— ë‰´ìŠ¤ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
    
    async def _arun(self, query: str = "ìµœì‹ ") -> str:
        """ë¹„ë™ê¸° ìµœì‹  ë‰´ìŠ¤ ì¡°íšŒ ì‹¤í–‰"""
        return self._run(query)


class DatabaseStatsTool(BaseTool):
    """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ ë„êµ¬"""
    
    name: str = "database_stats"
    description: str = """
    í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë‰´ìŠ¤ í†µê³„ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    ì‚¬ìš© ì˜ˆì‹œ:
    - "ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ"
    - "ë‰´ìŠ¤ ê°œìˆ˜"
    - "í†µê³„ ì •ë³´"
    
    ì…ë ¥: "stats" ë˜ëŠ” "í†µê³„" ë“±ì˜ í‚¤ì›Œë“œ
    ì¶œë ¥: ì „ì²´ ë‰´ìŠ¤ ê°œìˆ˜, ì„ë² ë”© ì²˜ë¦¬ í˜„í™© ë“±ì˜ í†µê³„
    """
    
    vector_service: Any = Field(description="ë²¡í„° ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤")
    
    def _run(self, query: str = "í†µê³„") -> str:
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ ì‹¤í–‰"""
        try:
            logger.info(f"ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ ì‹¤í–‰: {query}")
            
            # ì§ì ‘ DB ì—°ê²°ë¡œ í†µê³„ ì¡°íšŒ (ë¹„ë™ê¸° ë£¨í”„ ì¶©ëŒ ë°©ì§€)
            try:
                import psycopg2
                from psycopg2.extras import RealDictCursor
                
                # PgVector DBì— ì§ì ‘ ì—°ê²°
                conn = psycopg2.connect(
                    host='localhost',
                    port=5435,
                    database='mydb',
                    user='myuser',
                    password='mypassword'
                )
                
                with conn.cursor(cursor_factory=RealDictCursor) as cur:
                    # í†µê³„ ì •ë³´ ì¡°íšŒ
                    cur.execute("""
                        SELECT 
                            COUNT(*) as total_news,
                            COUNT(CASE WHEN embedding IS NOT NULL THEN 1 END) as news_with_embedding,
                            COUNT(CASE WHEN embedding IS NULL THEN 1 END) as news_without_embedding
                        FROM crypto_news
                    """)
                    
                    result = cur.fetchone()
                    
                    total_news = result['total_news']
                    news_with_embedding = result['news_with_embedding'] 
                    news_without_embedding = result['news_without_embedding']
                    
                    if total_news > 0:
                        embedding_coverage = (news_with_embedding / total_news) * 100
                    else:
                        embedding_coverage = 0
                    
                    stats = {
                        'total_news': total_news,
                        'news_with_embedding': news_with_embedding,
                        'news_without_embedding': news_without_embedding,
                        'embedding_coverage': embedding_coverage
                    }
                
                conn.close()
                
            except Exception as direct_db_error:
                logger.error(f"ì§ì ‘ DB í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {direct_db_error}")
                
                # ê¸°ì¡´ ë²¡í„° ì„œë¹„ìŠ¤ ì‚¬ìš© (ë°±ì—…)
                try:
                    # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì´ë²¤íŠ¸ ë£¨í”„ê°€ ìˆëŠ”ì§€ í™•ì¸
                    try:
                        current_loop = asyncio.get_running_loop()
                        # ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ìˆìœ¼ë©´ ìƒˆ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
                        import concurrent.futures
                        import threading
                        
                        def get_stats():
                            new_loop = asyncio.new_event_loop()
                            asyncio.set_event_loop(new_loop)
                            try:
                                return new_loop.run_until_complete(
                                    self.vector_service.get_database_stats()
                                )
                            finally:
                                new_loop.close()
                        
                        with concurrent.futures.ThreadPoolExecutor() as executor:
                            future = executor.submit(get_stats)
                            stats = future.result(timeout=10)
                            
                    except RuntimeError:
                        # ì‹¤í–‰ ì¤‘ì¸ ë£¨í”„ê°€ ì—†ìœ¼ë©´ ìƒˆ ë£¨í”„ ìƒì„±
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                        try:
                            stats = loop.run_until_complete(
                                self.vector_service.get_database_stats()
                            )
                        finally:
                            loop.close()
                            
                except Exception as backup_error:
                    logger.error(f"ë°±ì—… í†µê³„ ì¡°íšŒë„ ì‹¤íŒ¨: {backup_error}")
                    stats = None
            
            if not stats:
                return "ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì •ë³´ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
            # ê²°ê³¼ í¬ë§·íŒ…
            total_news = stats.get('total_news', 0)
            news_with_embedding = stats.get('news_with_embedding', 0)
            news_without_embedding = stats.get('news_without_embedding', 0)
            embedding_coverage = stats.get('embedding_coverage', 0)
            
            formatted_stats = "ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì •ë³´:\n\n"
            formatted_stats += f"ğŸ“° **ì „ì²´ ë‰´ìŠ¤ ê°œìˆ˜**: {total_news:,}ê°œ\n"
            formatted_stats += f"âœ… **ì„ë² ë”© ì²˜ë¦¬ ì™„ë£Œ**: {news_with_embedding:,}ê°œ\n"
            formatted_stats += f"â³ **ì„ë² ë”© ì²˜ë¦¬ ëŒ€ê¸°**: {news_without_embedding:,}ê°œ\n"
            formatted_stats += f"ğŸ“ˆ **ì²˜ë¦¬ ì™„ë£Œìœ¨**: {embedding_coverage:.1f}%\n\n"
            
            # ìƒíƒœ í‰ê°€
            if embedding_coverage >= 90:
                status = "ğŸŸ¢ ìš°ìˆ˜í•œ ìƒíƒœì…ë‹ˆë‹¤!"
            elif embedding_coverage >= 70:
                status = "ğŸŸ¡ ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤."
            else:
                status = "ğŸ”´ ì„ë² ë”© ì²˜ë¦¬ê°€ ë” í•„ìš”í•©ë‹ˆë‹¤."
            
            formatted_stats += f"ğŸ’¡ **ìƒíƒœ í‰ê°€**: {status}\n"
            
            logger.info(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ ì™„ë£Œ")
            return formatted_stats
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return f"ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    
    async def _arun(self, query: str = "í†µê³„") -> str:
        """ë¹„ë™ê¸° ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ ì‹¤í–‰"""
        return self._run(query)
